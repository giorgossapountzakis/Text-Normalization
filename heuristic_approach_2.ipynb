{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Set, Tuple\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text_normalization(csv_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Analyze a text normalization dataset to identify patterns in character preservation\n",
    "    across different scripts and normalization patterns.\n",
    "    \n",
    "    Args:\n",
    "        csv_path: Path to the CSV file containing the text normalization dataset\n",
    "    \"\"\"\n",
    "    print(f\"Loading dataset from {csv_path}...\")\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    \n",
    "\n",
    "    df = df.rename(columns={\n",
    "            'raw_comp_writers_text': 'raw',\n",
    "            'CLEAN_TEXT': 'clean'\n",
    "        })\n",
    "    \n",
    "    # Handle NaN values\n",
    "    df['clean'] = df['clean'].fillna('')\n",
    "    \n",
    "    # 1. Analyze script preservation\n",
    "    script_stats = analyze_script_preservation(df)\n",
    "    \n",
    "    # 2. Analyze normalization patterns\n",
    "    pattern_stats = analyze_normalization_patterns(df)\n",
    "    \n",
    "    # 3. Visualize results\n",
    "    visualize_results(script_stats, pattern_stats)\n",
    "    \n",
    "    # 4. Print summary\n",
    "    print_summary(script_stats, pattern_stats)\n",
    "\n",
    "def get_script_name(char: str) -> str:\n",
    "    \"\"\"\n",
    "    Identify the script of a character.\n",
    "    \n",
    "    Args:\n",
    "        char: A single character\n",
    "        \n",
    "    Returns:\n",
    "        The name of the script\n",
    "    \"\"\"\n",
    "    code = ord(char)\n",
    "    \n",
    "    # Latin-based diacritics - we'll categorize basic Latin + Latin-1 Supplement with diacritics\n",
    "    if code < 0x0100:\n",
    "        # Check if it has diacritics\n",
    "        if unicodedata.combining(char) or unicodedata.decomposition(char):\n",
    "            return \"Latin-diacritics\"\n",
    "        return \"Basic-Latin\"\n",
    "    \n",
    "    # Other scripts\n",
    "    if 0x0400 <= code <= 0x04FF:\n",
    "        return \"Cyrillic\"\n",
    "    if 0x0600 <= code <= 0x06FF:\n",
    "        return \"Arabic\"\n",
    "    if 0x0900 <= code <= 0x097F:\n",
    "        return \"Devanagari\"\n",
    "    if 0x0E00 <= code <= 0x0E7F:\n",
    "        return \"Thai\"\n",
    "    if 0x1100 <= code <= 0x11FF or 0xAC00 <= code <= 0xD7AF:\n",
    "        return \"Korean\"\n",
    "    if 0x3040 <= code <= 0x309F:\n",
    "        return \"Hiragana\"\n",
    "    if 0x30A0 <= code <= 0x30FF:\n",
    "        return \"Katakana\"\n",
    "    if 0x4E00 <= code <= 0x9FFF:\n",
    "        return \"CJK\"\n",
    "    \n",
    "    # For all other scripts, check unicode database\n",
    "    try:\n",
    "        script = unicodedata.name(char).split()[0]\n",
    "        return script\n",
    "    except:\n",
    "        return \"Other\"\n",
    "\n",
    "def get_scripts_in_text(text: str) -> Set[str]:\n",
    "    \"\"\"\n",
    "    Identify all scripts present in a text.\n",
    "    \n",
    "    Args:\n",
    "        text: A string of text\n",
    "        \n",
    "    Returns:\n",
    "        A set of script names\n",
    "    \"\"\"\n",
    "    scripts = set()\n",
    "    for char in text:\n",
    "        if not char.isspace() and not char.isascii():\n",
    "            script = get_script_name(char)\n",
    "            scripts.add(script)\n",
    "    return scripts\n",
    "\n",
    "def analyze_script_preservation(df: pd.DataFrame, sample_size: int = 5000) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze how different scripts are preserved in the normalization process.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing 'raw' and 'clean' text columns\n",
    "        sample_size: Number of rows to analyze (for speed)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with script preservation statistics\n",
    "    \"\"\"\n",
    "    print(\"\\nAnalyzing script preservation...\")\n",
    "    \n",
    "    # Sample the dataframe if it's large\n",
    "    if len(df) > sample_size:\n",
    "        analysis_df = df.sample(sample_size, random_state=42)\n",
    "    else:\n",
    "        analysis_df = df\n",
    "    \n",
    "    script_stats = defaultdict(lambda: {'total': 0, 'preserved': 0})\n",
    "    non_latin_rows = 0\n",
    "    preserved_rows = 0\n",
    "    \n",
    "    for i, row in analysis_df.iterrows():\n",
    "        raw = row['raw']\n",
    "        clean = row['clean']\n",
    "        \n",
    "        # Skip if raw is empty\n",
    "        if not raw or raw.isspace():\n",
    "            continue\n",
    "            \n",
    "        # Get scripts in raw and clean text\n",
    "        raw_scripts = get_scripts_in_text(raw)\n",
    "        clean_scripts = get_scripts_in_text(clean)\n",
    "        \n",
    "        # Track rows with non-Latin characters\n",
    "        if raw_scripts:\n",
    "            non_latin_rows += 1\n",
    "            if clean_scripts:\n",
    "                preserved_rows += 1\n",
    "        \n",
    "        # For each script in raw, check if it's preserved in clean\n",
    "        for script in raw_scripts:\n",
    "            script_stats[script]['total'] += 1\n",
    "            if script in clean_scripts:\n",
    "                script_stats[script]['preserved'] += 1\n",
    "    \n",
    "    # Calculate preservation rate\n",
    "    if non_latin_rows > 0:\n",
    "        overall_preservation_rate = (preserved_rows / non_latin_rows) * 100\n",
    "    else:\n",
    "        overall_preservation_rate = 0\n",
    "    \n",
    "    # Add overall rate to the stats\n",
    "    script_stats['overall'] = {\n",
    "        'total': non_latin_rows,\n",
    "        'preserved': preserved_rows,\n",
    "        'rate': overall_preservation_rate\n",
    "    }\n",
    "    \n",
    "    return script_stats\n",
    "\n",
    "def analyze_normalization_patterns(df: pd.DataFrame, sample_size: int = 3000) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze common normalization patterns in the dataset.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing 'raw' and 'clean' text columns\n",
    "        sample_size: Number of rows to analyze (for speed)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with normalization pattern statistics\n",
    "    \"\"\"\n",
    "    print(\"\\nAnalyzing normalization patterns...\")\n",
    "    \n",
    "    # Sample the dataframe if it's large\n",
    "    if len(df) > sample_size:\n",
    "        analysis_df = df.sample(sample_size, random_state=42)\n",
    "    else:\n",
    "        analysis_df = df\n",
    "    \n",
    "    # Define pattern recognition regexes\n",
    "    publishing_terms_regex = re.compile(r'PUBLISHING|COPYRIGHT|RIGHTS|ADMIN|STUDIO|MUSIC|ENTERTAINMENT', re.IGNORECASE)\n",
    "    business_entities_regex = re.compile(r'LIMITED|LTD|LLC|INC|CORP|GMBH|PTY|S\\.A\\.|N\\.V\\.|CO\\.|ASSOCIATES', re.IGNORECASE)\n",
    "    \n",
    "    # Initialize counters\n",
    "    patterns = {\n",
    "        'publishing_terms_removed': 0,\n",
    "        'business_entities_removed': 0,\n",
    "        'non_latin_rows_empty': 0,\n",
    "        'name_structure_changed': 0,\n",
    "        'total_analyzed': len(analysis_df)\n",
    "    }\n",
    "    \n",
    "    for i, row in analysis_df.iterrows():\n",
    "        raw = row['raw']\n",
    "        clean = row['clean']\n",
    "        \n",
    "        # Skip if raw is empty\n",
    "        if not raw or raw.isspace():\n",
    "            continue\n",
    "            \n",
    "        # Check if publishing terms are removed\n",
    "        if publishing_terms_regex.search(raw) and not publishing_terms_regex.search(clean):\n",
    "            patterns['publishing_terms_removed'] += 1\n",
    "            \n",
    "        # Check if business entities are removed\n",
    "        if business_entities_regex.search(raw) and not business_entities_regex.search(clean):\n",
    "            patterns['business_entities_removed'] += 1\n",
    "            \n",
    "        # Check if non-Latin rows are normalized to empty strings\n",
    "        if get_scripts_in_text(raw) and not clean:\n",
    "            patterns['non_latin_rows_empty'] += 1\n",
    "            \n",
    "        # Check if name structure changed (e.g., \"Last, First\" to \"First Last\")\n",
    "        if \",\" in raw and \",\" not in clean:\n",
    "            # Simple heuristic to detect name inversions\n",
    "            raw_parts = [part.strip() for part in raw.split(\",\")]\n",
    "            if len(raw_parts) == 2 and f\"{raw_parts[1]} {raw_parts[0]}\" == clean:\n",
    "                patterns['name_structure_changed'] += 1\n",
    "    \n",
    "    return patterns\n",
    "\n",
    "def print_summary(script_stats: Dict, pattern_stats: Dict) -> None:\n",
    "    \"\"\"\n",
    "    Print a summary of the analysis results.\n",
    "    \n",
    "    Args:\n",
    "        script_stats: Dictionary with script preservation statistics\n",
    "        pattern_stats: Dictionary with normalization pattern statistics\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"                   TEXT NORMALIZATION ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Overall preservation rate\n",
    "    print(f\"\\nNon-Latin Character Preservation:\")\n",
    "    print(f\"  Overall preservation rate: {script_stats['overall']['rate']:.2f}%\")\n",
    "    print(f\"  Rows with non-Latin characters: {script_stats['overall']['total']}\")\n",
    "    print(f\"  Rows with preserved non-Latin characters: {script_stats['overall']['preserved']}\")\n",
    "    \n",
    "    # Script-specific preservation rates\n",
    "    print(\"\\nPreservation rates by script:\")\n",
    "    for script, stats in sorted(script_stats.items(), key=lambda x: (-(x[1]['preserved'] / x[1]['total'] if x[1]['total'] > 0 else 0), x[0])):\n",
    "        if script != 'overall' and stats['total'] > 0:\n",
    "            rate = (stats['preserved'] / stats['total']) * 100\n",
    "            print(f\"  {script}: {stats['preserved']}/{stats['total']} ({rate:.2f}%)\")\n",
    "    \n",
    "    # Normalization patterns\n",
    "    print(\"\\nNormalization Patterns:\")\n",
    "    total = pattern_stats['total_analyzed']\n",
    "    print(f\"  Publishing terms removed: {pattern_stats['publishing_terms_removed']} ({pattern_stats['publishing_terms_removed']/total*100:.2f}%)\")\n",
    "    print(f\"  Business entities removed: {pattern_stats['business_entities_removed']} ({pattern_stats['business_entities_removed']/total*100:.2f}%)\")\n",
    "    print(f\"  Non-Latin rows normalized to empty: {pattern_stats['non_latin_rows_empty']} ({pattern_stats['non_latin_rows_empty']/total*100:.2f}%)\")\n",
    "    print(f\"  Name structure changed: {pattern_stats['name_structure_changed']} ({pattern_stats['name_structure_changed']/total*100:.2f}%)\")\n",
    "    \n",
    "    # Summary of findings\n",
    "    print(\"\\nKey Findings:\")\n",
    "    print(\"  * The dataset shows selective character preservation across different scripts\")\n",
    "    print(\"  * Business terms and publishing-related information are commonly removed\")\n",
    "    if pattern_stats['non_latin_rows_empty'] > 0:\n",
    "        print(f\"  * {pattern_stats['non_latin_rows_empty']} rows with non-Latin characters were normalized to empty strings\")\n",
    "    \n",
    "\n",
    "def visualize_results(script_stats: Dict, pattern_stats: Dict) -> None:\n",
    "    \"\"\"\n",
    "    Visualize the analysis results using matplotlib.\n",
    "    \n",
    "    Args:\n",
    "        script_stats: Dictionary with script preservation statistics\n",
    "        pattern_stats: Dictionary with normalization pattern statistics\n",
    "    \"\"\"\n",
    "    # Set the style\n",
    "    plt.style.use('ggplot')\n",
    "    \n",
    "    # Create a figure with 2 subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # 1. Script preservation rates\n",
    "    script_data = []\n",
    "    for script, stats in script_stats.items():\n",
    "        if script != 'overall' and stats['total'] >= 3:  # Only include scripts with enough data\n",
    "            rate = (stats['preserved'] / stats['total']) * 100 if stats['total'] > 0 else 0\n",
    "            script_data.append((script, rate, stats['total']))\n",
    "    \n",
    "    # Sort by preservation rate\n",
    "    script_data.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Extract data for plotting\n",
    "    scripts = [item[0] for item in script_data]\n",
    "    rates = [item[1] for item in script_data]\n",
    "    counts = [item[2] for item in script_data]\n",
    "    \n",
    "    # Create the bar chart\n",
    "    bars = ax1.barh(scripts, rates, color='skyblue')\n",
    "    \n",
    "    # Add count labels\n",
    "    for i, (bar, count) in enumerate(zip(bars, counts)):\n",
    "        ax1.text(\n",
    "            bar.get_width() + 2,\n",
    "            bar.get_y() + bar.get_height()/2,\n",
    "            f'n={count}',\n",
    "            va='center',\n",
    "            fontsize=8\n",
    "        )\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax1.set_xlabel('Preservation Rate (%)')\n",
    "    ax1.set_title('Script Preservation Rates')\n",
    "    ax1.set_xlim(0, 110)  # Leave room for the count labels\n",
    "    \n",
    "    # 2. Normalization patterns\n",
    "    pattern_labels = [\n",
    "        'Publishing terms\\nremoved',\n",
    "        'Business entities\\nremoved',\n",
    "        'Non-Latin rows\\nto empty',\n",
    "        'Name structure\\nchanged'\n",
    "    ]\n",
    "    \n",
    "    pattern_values = [\n",
    "        pattern_stats['publishing_terms_removed'] / pattern_stats['total_analyzed'] * 100,\n",
    "        pattern_stats['business_entities_removed'] / pattern_stats['total_analyzed'] * 100,\n",
    "        pattern_stats['non_latin_rows_empty'] / pattern_stats['total_analyzed'] * 100,\n",
    "        pattern_stats['name_structure_changed'] / pattern_stats['total_analyzed'] * 100\n",
    "    ]\n",
    "    \n",
    "    # Create the bar chart\n",
    "    pattern_bars = ax2.bar(pattern_labels, pattern_values, color='lightcoral')\n",
    "    \n",
    "    # Add count labels\n",
    "    for i, bar in enumerate(pattern_bars):\n",
    "        count = [\n",
    "            pattern_stats['publishing_terms_removed'],\n",
    "            pattern_stats['business_entities_removed'],\n",
    "            pattern_stats['non_latin_rows_empty'],\n",
    "            pattern_stats['name_structure_changed']\n",
    "        ][i]\n",
    "        ax2.text(\n",
    "            bar.get_x() + bar.get_width()/2,\n",
    "            bar.get_height() + 1,\n",
    "            f'n={count}',\n",
    "            ha='center',\n",
    "            fontsize=8\n",
    "        )\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax2.set_ylabel('Percentage of Analyzed Rows (%)')\n",
    "    ax2.set_title('Normalization Patterns')\n",
    "    ax2.set_ylim(0, max(pattern_values) * 1.2)  # Leave room for the count labels\n",
    "    \n",
    "    # Add an overall title\n",
    "    plt.suptitle('Text Normalization Analysis', fontsize=16)\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.savefig('normalization_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"\\nVisualization saved as 'normalization_analysis.png'\")\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from normalization_assesment_dataset_10k.csv...\n",
      "Dataset shape: (10000, 2)\n",
      "\n",
      "Analyzing script preservation...\n",
      "\n",
      "Analyzing normalization patterns...\n",
      "\n",
      "Visualization saved as 'normalization_analysis.png'\n",
      "\n",
      "======================================================================\n",
      "                   TEXT NORMALIZATION ANALYSIS SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Non-Latin Character Preservation:\n",
      "  Overall preservation rate: 52.88%\n",
      "  Rows with non-Latin characters: 713\n",
      "  Rows with preserved non-Latin characters: 377\n",
      "\n",
      "Preservation rates by script:\n",
      "  DOUBLE: 1/1 (100.00%)\n",
      "  EN: 1/1 (100.00%)\n",
      "  PRIME: 1/1 (100.00%)\n",
      "  WEST: 1/1 (100.00%)\n",
      "  Basic-Latin: 10/11 (90.91%)\n",
      "  RIGHT: 25/29 (86.21%)\n",
      "  HYPHEN: 6/7 (85.71%)\n",
      "  Latin-diacritics: 303/366 (82.79%)\n",
      "  LEFT: 9/11 (81.82%)\n",
      "  ZERO: 6/9 (66.67%)\n",
      "  LATIN: 45/92 (48.91%)\n",
      "  KHMER: 1/4 (25.00%)\n",
      "  Cyrillic: 1/64 (1.56%)\n",
      "  Arabic: 0/14 (0.00%)\n",
      "  CJK: 0/108 (0.00%)\n",
      "  COMBINING: 0/1 (0.00%)\n",
      "  FULLWIDTH: 0/2 (0.00%)\n",
      "  GREEK: 0/3 (0.00%)\n",
      "  HANGUL: 0/1 (0.00%)\n",
      "  HEBREW: 0/5 (0.00%)\n",
      "  Hiragana: 0/17 (0.00%)\n",
      "  Katakana: 0/16 (0.00%)\n",
      "  Korean: 0/28 (0.00%)\n",
      "  Thai: 0/2 (0.00%)\n",
      "  WAVE: 0/1 (0.00%)\n",
      "  WHITE: 0/1 (0.00%)\n",
      "\n",
      "Normalization Patterns:\n",
      "  Publishing terms removed: 97 (3.23%)\n",
      "  Business entities removed: 37 (1.23%)\n",
      "  Non-Latin rows normalized to empty: 174 (5.80%)\n",
      "  Name structure changed: 0 (0.00%)\n",
      "\n",
      "Key Findings:\n",
      "  * The dataset shows selective character preservation across different scripts\n",
      "  * Business terms and publishing-related information are commonly removed\n",
      "  * 174 rows with non-Latin characters were normalized to empty strings\n"
     ]
    }
   ],
   "source": [
    "analyze_text_normalization('normalization_assesment_dataset_10k.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
