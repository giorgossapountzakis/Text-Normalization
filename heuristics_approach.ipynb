{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('normalization_assesment_dataset_10k.csv')\n",
    "print(\"Dataset shape: \",df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_na(df):    \n",
    "    # Calculate null values for each column\n",
    "    null_counts = df.isnull().sum()\n",
    "    # Calculate percentage of null values\n",
    "    null_percentages = (null_counts / len(df)) * 100\n",
    "    print('null_percentages',null_percentages)\n",
    "    if all(null_percentages[column] for column in df.columns)  and df.shape[0]>=10000:\n",
    "        new_df = df.dropna()\n",
    "        print(new_df.shape)\n",
    "        return new_df\n",
    "    return df\n",
    "\n",
    "df = handle_na(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_char=0\n",
    "max_words=0\n",
    "for row in df['raw_comp_writers_text']:\n",
    "    if len(str(row).split(' ')) > max_words:\n",
    "        max_words = len(str(row).split(' '))\n",
    "    if len(row) > max_char:\n",
    "       max_char=len(row)\n",
    "print(max_char)\n",
    "print(max_words)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_word_counts(df_column):\n",
    "   word_counts = df_column.str.split().str.len()\n",
    "   \n",
    "   plt.figure(figsize=(10, 6))\n",
    "   plt.hist(word_counts, bins=20, edgecolor='black')\n",
    "   plt.title('Distribution of Words per Row')\n",
    "   plt.xlabel('Number of Words')\n",
    "   plt.ylabel('Number of rows')\n",
    "   plt.grid(True, alpha=0.3)\n",
    "   plt.show()\n",
    "   \n",
    "   print(f\"Average words per row: {word_counts.mean():.1f}\")\n",
    "   print(f\"Max words: {word_counts.max()}\")\n",
    "\n",
    "plot_word_counts(df['raw_comp_writers_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_column='raw_comp_writers_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def find_non_alpha(df, column_name):\n",
    "    # Combine all strings in column\n",
    "    text = ' '.join(df[column_name].astype(str))\n",
    "    # Find all non-alphabetical characters\n",
    "    non_alpha = re.findall(r'[^a-zA-Z\\s]', text)\n",
    "    # Count occurrences\n",
    "    char_counts = {char: text.count(char) for char in set(non_alpha)}\n",
    "    return char_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "non_alpha_chars = find_non_alpha(df, raw_column)\n",
    "print(\"Non-alphabetical characters found:\")\n",
    "print(non_alpha_chars)\n",
    "print(len(non_alpha_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_punctuation_examples(df, column_name):\n",
    "   \"\"\"Print one row per punctuation mark found\"\"\"\n",
    "   import string\n",
    "\n",
    "   shown_examples = set()\n",
    "   \n",
    "   for idx, row in df.iterrows():\n",
    "       text = str(row[column_name])\n",
    "       for char in text:\n",
    "           if char in string.punctuation and char not in shown_examples:\n",
    "               print(f\"\\nPunctuation '{char}' in row {idx}:\")\n",
    "               print(row)\n",
    "               shown_examples.add(char)\n",
    "\n",
    "punct_marks = find_punctuation_examples(df, 'raw_comp_writers_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def find_non_letter_examples(df, column_name):\n",
    "    \"\"\"Print one row per non-letter character found\"\"\"\n",
    "    \n",
    "    shown_examples = set()\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        text = str(row[column_name])\n",
    "        for char in text:\n",
    "            # Check if character is not a letter and not whitespace\n",
    "            if not char in string.ascii_letters and not char.isspace() and char not in shown_examples:\n",
    "                print(f\"\\nNon-letter character '{char}' in row {idx}:\")\n",
    "                print(row)\n",
    "                shown_examples.add(char)\n",
    "\n",
    "non_letter_chars = find_non_letter_examples(df, raw_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_angled_brackets_content(df, column_name):\n",
    "    \"\"\"Extract strings between < > characters in a dataframe column\"\"\"\n",
    "    import re\n",
    "    \n",
    "    bracketed_content = set()\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        text = str(row[column_name])\n",
    "        # Find all matches between < >\n",
    "        matches = re.findall(r'<([^>]+)>', text)\n",
    "        if matches:\n",
    "            bracketed_content.update(matches)\n",
    "    \n",
    "    return list(bracketed_content)\n",
    "\n",
    "\n",
    "brackets = find_angled_brackets_content(df, raw_column)\n",
    "print(\"\\nUnique bracketed content found:\", brackets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic_clean(raw_text, keywords):\n",
    "   \"\"\"Clean text using heuristic rules\"\"\"\n",
    "   import string\n",
    "   \n",
    "   # Remove keywords\n",
    "   clean_text = raw_text\n",
    "   for keyword in keywords:\n",
    "       clean_text = clean_text.replace(keyword, '')\n",
    "   \n",
    "   # Replace & and comma with /\n",
    "   clean_text = clean_text.replace(' & ', '/').replace('&', '/').replace(',', '/')\n",
    "   \n",
    "   # Replace punctuation except / with space\n",
    "   trans = str.maketrans({p: ' ' for p in string.punctuation if p != '/'})\n",
    "   clean_text = clean_text.translate(trans)\n",
    "   \n",
    "   # Replace multiple spaces with single space\n",
    "   clean_text = ' '.join(clean_text.split())\n",
    "   \n",
    "   # Remove spaces around /\n",
    "   clean_text = re.sub(r'\\s*/\\s*', '/', clean_text)\n",
    "\n",
    "   return clean_text\n",
    "\n",
    "\n",
    "text = '<Unknown>/Wright, Justyce Kaseem'\n",
    "clean_text = heuristic_clean(text, brackets)\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\n",
    "    # Publishing and Rights Management\n",
    "    'COPYRIGHT CONTROL', 'PUBLISHING', 'MUSIC PUBLISHING', 'ALL RIGHTS RESERVED',\n",
    "    'RIGHTS ADMINISTERED', 'RIGHTS MANAGED', 'RIGHTS CONTROLLED',\n",
    "    'PERFORMANCE RIGHTS', 'MECHANICAL RIGHTS', 'SYNC RIGHTS',\n",
    "    'ADMINISTERED BY', 'LICENSED TO', 'CONTROLLED BY',\n",
    "    \n",
    "    # Business Entities\n",
    "    'LIMITED', 'LTD', 'LLC', 'INC', 'INCORPORATED', 'CORP', 'CORPORATION',\n",
    "    'GMBH', 'PTY', 'S.A.', 'N.V.', 'AG', 'CO', 'COMPANY',\n",
    "    \n",
    "    # Music Industry Terms\n",
    "    'MUSIC', 'SONGS', 'PRODUCTIONS', 'ENTERTAINMENT', 'RECORDS',\n",
    "    'RECORDINGS', 'LABEL', 'STUDIO', 'GROUP', 'BAND',\n",
    "    \n",
    "    # Major Companies and Common Affiliates\n",
    "    'SONY', 'ATV', 'SONY/ATV', 'BMG', 'EMI', 'UNIVERSAL',\n",
    "    'WARNER', 'WARNER CHAPPELL', 'KOBALT', 'BMI', 'ASCAP', 'SESAC',\n",
    "    'COLUMBIA', 'ATLANTIC', 'CAPITOL', 'MOTOWN', 'RCA',\n",
    "    \n",
    "    # Professional Designations\n",
    "    'MUSIKVERLAG', 'Ã‰DITIONS', 'EDITIONS', 'VERLAG',\n",
    "    'MUSIC GROUP', 'MEDIA', 'PARTNERS', 'ASSOCIATES',\n",
    "    \n",
    "    # Common Suffixes and Descriptors\n",
    "    'WORLDWIDE', 'INTERNATIONAL', 'GLOBAL', 'MANAGEMENT',\n",
    "    'HOLDINGS', 'VENTURES', 'ENTERPRISES', 'WORKS',\n",
    "    \n",
    "    # Rights Organizations\n",
    "    'PERFORMING RIGHTS', 'SOCIETY', 'ORGANIZATION', 'ASSOCIATION',\n",
    "    'COLLECTION SOCIETY', 'RIGHTS SOCIETY',\n",
    "    \n",
    "    # Digital and Modern Terms\n",
    "    'DIGITAL', 'DISTRIBUTION', 'STREAMING', 'LICENSING',\n",
    "    \n",
    "    # Legal and Administrative\n",
    "    'ADMINISTERED', 'REPRESENTS', 'REPRESENTED BY',\n",
    "    'ON BEHALF OF', 'C/O', 'CARE OF',\n",
    "    \n",
    "    # Geographical Indicators\n",
    "    '(UK)', '(US)', '(EU)', '(JP)', 'UK', 'USA', 'AMERICA',\n",
    "    'EUROPEAN', 'INTERNATIONAL', 'GLOBAL'\n",
    "]\n",
    "\n",
    "# Clean up the keywords list (remove duplicates, strip whitespace)\n",
    "keywords = list(set([k.strip() for k in keywords]))\n",
    "# Sort by length (longer phrases first to avoid partial replacements)\n",
    "keywords = sorted(keywords, key=len, reverse=True)\n",
    "print(keywords)\n",
    "keywords=keywords+brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Split data\n",
    "X = df['raw_comp_writers_text']\n",
    "y = df['CLEAN_TEXT']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Make predictions using heuristic_clean\n",
    "y_pred = [heuristic_clean(text, keywords) for text in X_test]\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.3f}')\n",
    "print(f'F1 Score: {f1:.3f}')\n",
    "\n",
    "# Show some examples\n",
    "print('\\nExample predictions:')\n",
    "for i in range(5):\n",
    "   print(f'\\nInput: {X_test.iloc[i]}')\n",
    "   print(f'Predicted: {y_pred[i]}')\n",
    "   print(f'Expected: {y_test.iloc[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
