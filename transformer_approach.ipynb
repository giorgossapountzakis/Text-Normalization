{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import AdamW\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Check if CUDA is available and set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (10000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_comp_writers_text</th>\n",
       "      <th>CLEAN_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jordan Riley/Adam Argyle/Martin Brammer</td>\n",
       "      <td>Jordan Riley/Adam Argyle/Martin Brammer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Martin Hygård</td>\n",
       "      <td>Martin Hygård</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jesse Robinson/Greg Phillips/Kishaun Bailey/Ka...</td>\n",
       "      <td>Jesse Robinson/Greg Phillips/Kishaun Bailey/Ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mendel Brikman</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alvin Lee</td>\n",
       "      <td>Alvin Lee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               raw_comp_writers_text  \\\n",
       "0            Jordan Riley/Adam Argyle/Martin Brammer   \n",
       "1                                      Martin Hygård   \n",
       "2  Jesse Robinson/Greg Phillips/Kishaun Bailey/Ka...   \n",
       "3                                     Mendel Brikman   \n",
       "4                                          Alvin Lee   \n",
       "\n",
       "                                          CLEAN_TEXT  \n",
       "0            Jordan Riley/Adam Argyle/Martin Brammer  \n",
       "1                                      Martin Hygård  \n",
       "2  Jesse Robinson/Greg Phillips/Kishaun Bailey/Ka...  \n",
       "3                                                NaN  \n",
       "4                                          Alvin Lee  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv(\"normalization_assesment_dataset_10k.csv\")\n",
    "print(\"Dataset shape: \", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null_percentages raw_comp_writers_text     0.01\n",
      "CLEAN_TEXT               13.41\n",
      "dtype: float64\n",
      "(8659, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_comp_writers_text</th>\n",
       "      <th>CLEAN_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jordan Riley/Adam Argyle/Martin Brammer</td>\n",
       "      <td>Jordan Riley/Adam Argyle/Martin Brammer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Martin Hygård</td>\n",
       "      <td>Martin Hygård</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jesse Robinson/Greg Phillips/Kishaun Bailey/Ka...</td>\n",
       "      <td>Jesse Robinson/Greg Phillips/Kishaun Bailey/Ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alvin Lee</td>\n",
       "      <td>Alvin Lee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Haddag Samir/MusicAlligator</td>\n",
       "      <td>Haddag Samir</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               raw_comp_writers_text  \\\n",
       "0            Jordan Riley/Adam Argyle/Martin Brammer   \n",
       "1                                      Martin Hygård   \n",
       "2  Jesse Robinson/Greg Phillips/Kishaun Bailey/Ka...   \n",
       "4                                          Alvin Lee   \n",
       "5                        Haddag Samir/MusicAlligator   \n",
       "\n",
       "                                          CLEAN_TEXT  \n",
       "0            Jordan Riley/Adam Argyle/Martin Brammer  \n",
       "1                                      Martin Hygård  \n",
       "2  Jesse Robinson/Greg Phillips/Kishaun Bailey/Ka...  \n",
       "4                                          Alvin Lee  \n",
       "5                                       Haddag Samir  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def handle_na(df):\n",
    "    # Calculate null values for each column\n",
    "    null_counts = df.isnull().sum()\n",
    "    # Calculate percentage of null values\n",
    "    null_percentages = (null_counts / len(df)) * 100\n",
    "    print(\"null_percentages\", null_percentages)\n",
    "    if all(null_percentages[column] for column in df.columns) and df.shape[0] >= 10000:\n",
    "        new_df = df.dropna()\n",
    "        print(new_df.shape)\n",
    "        return new_df\n",
    "    return df\n",
    "\n",
    "\n",
    "df = handle_na(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training samples: 6927\n",
      "Validation samples: 1732\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    df[\"raw_comp_writers_text\"].values,\n",
    "    df[\"CLEAN_TEXT\"].values,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextNormalizationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        \"\"\"\n",
    "        Initialize the dataset for text normalization\n",
    "\n",
    "        Args:\n",
    "            texts (list): List of raw input texts\n",
    "            labels (list): List of normalized (clean) texts\n",
    "            tokenizer: T5 tokenizer instance\n",
    "            max_length (int): Maximum sequence length\n",
    "        \"\"\"\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Prepare input text with a task-specific prefix\n",
    "        input_text = f\"normalize: {self.texts[idx]}\"\n",
    "\n",
    "        # Tokenize input and target texts\n",
    "        input_encoding = self.tokenizer(\n",
    "            input_text,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        target_encoding = self.tokenizer(\n",
    "            self.labels[idx],\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": input_encoding[\"attention_mask\"].flatten(),\n",
    "            \"labels\": target_encoding[\"input_ids\"].flatten(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer\n",
    "print(\"\\nInitializing tokenizer...\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")  # legacy= False\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TextNormalizationDataset(X_train, Y_train, tokenizer,max_length=128)\n",
    "val_dataset = TextNormalizationDataset(X_test, Y_test, tokenizer,max_length=128)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum tokens in dataset: 171\n"
     ]
    }
   ],
   "source": [
    "max_tokens = max(len(tokenizer.encode(text)) for text in df['raw_comp_writers_text'])\n",
    "print(f\"Maximum tokens in dataset: {max_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextNormalizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name=\"t5-small\",\n",
    "        device=device,\n",
    "    ):\n",
    "        self.device = device\n",
    "        print(f\"Loading {model_name} model...\")\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "        print(\"Model and tokenizer loaded successfully\")\n",
    "\n",
    "    def train(self, train_loader, val_loader, epochs=3, lr=3e-5, patience=3):\n",
    "        \"\"\"\n",
    "        Train the model with early stopping\n",
    "        \n",
    "        Args:\n",
    "            train_loader: Training data loader\n",
    "            val_loader: Validation data loader\n",
    "            epochs (int): Maximum number of training epochs\n",
    "            lr (float): Learning rate\n",
    "            patience (int): Number of epochs to wait for improvement before stopping\n",
    "        \"\"\"\n",
    "        optimizer = AdamW(self.model.parameters(), lr=lr)\n",
    "        best_val_loss = float(\"inf\")\n",
    "        patience_counter = 0\n",
    "        best_model_state = None\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "            # Training loop\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "\n",
    "            for batch in progress_bar:\n",
    "                input_ids = batch[\"input_ids\"].to(self.device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(self.device)\n",
    "                labels = batch[\"labels\"].to(self.device)\n",
    "\n",
    "                outputs = self.model(\n",
    "                    input_ids=input_ids, \n",
    "                    attention_mask=attention_mask, \n",
    "                    labels=labels\n",
    "                )\n",
    "\n",
    "                loss = outputs.loss\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "            # Validation loop\n",
    "            val_loss = self.evaluate(val_loader)\n",
    "\n",
    "            # Print epoch statistics\n",
    "            avg_train_loss = train_loss / len(train_loader)\n",
    "            print(f\"Average training loss: {avg_train_loss:.4f}\")\n",
    "            print(f\"Average validation loss: {val_loss:.4f}\")\n",
    "\n",
    "            # Early stopping logic\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                best_model_state = self.model.state_dict().copy()\n",
    "                torch.save(best_model_state, \"best_model2.pt\")\n",
    "                print(\"Saved best model checkpoint\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                print(f\"Validation loss didn't improve. Patience: {patience_counter}/{patience}\")\n",
    "\n",
    "            # Check if we should stop training\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"\\nEarly stopping triggered after epoch {epoch + 1}\")\n",
    "                print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "                # Restore best model\n",
    "                self.model.load_state_dict(best_model_state)\n",
    "                break\n",
    "\n",
    "    def evaluate(self, val_loader):\n",
    "        \"\"\"\n",
    "        Evaluate the model on validation data\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        val_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "                input_ids = batch[\"input_ids\"].to(self.device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(self.device)\n",
    "                labels = batch[\"labels\"].to(self.device)\n",
    "\n",
    "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "                val_loss += outputs.loss.item()\n",
    "\n",
    "        return val_loss / len(val_loader)\n",
    "\n",
    "    def normalize_text(self, text):\n",
    "        \"\"\"\n",
    "        Normalize a single text input\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "\n",
    "        # Prepare input\n",
    "        input_text = f\"normalize: {text}\"\n",
    "        inputs = self.tokenizer(\n",
    "            input_text,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=128,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Generate output\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                max_length=128,\n",
    "                num_beams=4,\n",
    "                early_stopping=True,\n",
    "            )\n",
    "\n",
    "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "normalizer = TextNormalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer.train(train_loader, val_loader, epochs=30,patience=2,lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with some examples\n",
    "test_examples = [\n",
    "    \"Mike Hoyer/JERRY CHESNUT/SONY/ATV MUSIC PUBLISHING (UK) LIMITED\",\n",
    "    \"<Unknown>/Wright, Justyce Kaseem\",\n",
    "    \"Pixouu/Abdou Gambetta/Copyright Control\",\n",
    "]\n",
    "\n",
    "print(\"\\nTesting the model with examples:\")\n",
    "for text in test_examples:\n",
    "    normalized = normalizer.normalize_text(text)\n",
    "    print(f\"\\nInput: {text}\")\n",
    "    print(f\"Output: {normalized}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(normalizer, val_loader):\n",
    "    normalizer.model.eval()\n",
    "    exact_matches = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Calculating metrics\"):\n",
    "            input_ids = batch[\"input_ids\"].to(normalizer.device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(normalizer.device)\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            # Generate predictions\n",
    "            outputs = normalizer.model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=128,\n",
    "                num_beams=4,\n",
    "                early_stopping=True,\n",
    "                temperature=1.0,        \n",
    "                top_k=20,            \n",
    "                top_p=8.0,\n",
    "                repetition_penalty=1.0  \n",
    "            )\n",
    "\n",
    "            # Decode predictions and labels\n",
    "            predictions = [normalizer.tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "            true_labels = [normalizer.tokenizer.decode(label, skip_special_tokens=True) for label in labels]\n",
    "\n",
    "            # Calculate metrics\n",
    "            exact_matches += sum(1 for pred, true in zip(predictions, true_labels) if pred == true)\n",
    "            total += len(predictions)\n",
    "\n",
    "    accuracy = exact_matches / total\n",
    "    print(f\"\\nExact match accuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "accuracy = calculate_accuracy(normalizer, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_exact_matches(predictions, true_labels):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of predictions that exactly match their true labels\n",
    "    \"\"\"\n",
    "    matches = sum(1 for pred, true in zip(predictions, true_labels) if pred.strip() == true.strip())\n",
    "    return matches / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "\n",
    "def calculate_token_f1(predictions, true_labels):\n",
    "    \"\"\"\n",
    "    Calculate F1 score based on shared tokens between prediction and true label\n",
    "    \"\"\"\n",
    "    def tokenize(text):\n",
    "        # Split on common delimiters and create a set of tokens\n",
    "        return set(token.strip() for token in text.replace('/', ' ').split())\n",
    "    \n",
    "    all_true_tokens = []\n",
    "    all_pred_tokens = []\n",
    "    \n",
    "    for pred, true in zip(predictions, true_labels):\n",
    "        true_tokens = tokenize(true)\n",
    "        pred_tokens = tokenize(pred)\n",
    "        \n",
    "        # Convert to binary presence/absence for each token\n",
    "        all_tokens = true_tokens.union(pred_tokens)\n",
    "        all_true_tokens.extend(1 if token in true_tokens else 0 for token in all_tokens)\n",
    "        all_pred_tokens.extend(1 if token in pred_tokens else 0 for token in all_tokens)\n",
    "    \n",
    "    return f1_score(all_true_tokens, all_pred_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_order_score(predictions, true_labels):\n",
    "    \"\"\"\n",
    "    Calculate how well the model preserves the correct order of names\n",
    "    \"\"\"\n",
    "    def get_ordered_names(text):\n",
    "        return [name.strip() for name in text.split('/')]\n",
    "    \n",
    "    correct_order = 0\n",
    "    total_pairs = 0\n",
    "    \n",
    "    for pred, true in zip(predictions, true_labels):\n",
    "        pred_names = get_ordered_names(pred)\n",
    "        true_names = get_ordered_names(true)\n",
    "        \n",
    "        # Check relative ordering of each pair of names\n",
    "        for i in range(len(true_names)):\n",
    "            for j in range(i + 1, len(true_names)):\n",
    "                if i < len(pred_names) and j < len(pred_names):\n",
    "                    if (pred_names[i] in true_names and \n",
    "                        pred_names[j] in true_names):\n",
    "                        if (true_names.index(pred_names[i]) < \n",
    "                            true_names.index(pred_names[j])):\n",
    "                            correct_order += 1\n",
    "                    total_pairs += 1\n",
    "    \n",
    "    return correct_order / total_pairs if total_pairs > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(normalizer, val_loader):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation of the text normalization model\n",
    "    \"\"\"\n",
    "    normalizer.model.eval()\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "    \n",
    "    print(\"Generating predictions...\")\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader):\n",
    "            # Generate predictions\n",
    "            outputs = normalizer.model.generate(\n",
    "                input_ids=batch['input_ids'].to(normalizer.device),\n",
    "                attention_mask=batch['attention_mask'].to(normalizer.device),\n",
    "                max_length=32,\n",
    "                num_beams=4,\n",
    "                early_stopping=True,\n",
    "                temperature=1.0,        \n",
    "                top_k=20,            \n",
    "                top_p=8.0,\n",
    "                repetition_penalty=1.0  \n",
    "            )\n",
    "            \n",
    "            # Decode predictions and true labels\n",
    "            predictions = [normalizer.tokenizer.decode(output, skip_special_tokens=True) \n",
    "                         for output in outputs]\n",
    "            true_labels = [normalizer.tokenizer.decode(label, skip_special_tokens=True) \n",
    "                         for label in batch['labels']]\n",
    "            \n",
    "            all_predictions.extend(predictions)\n",
    "            all_true_labels.extend(true_labels)\n",
    "    \n",
    "    # Calculate all metrics\n",
    "    exact_accuracy = calculate_exact_matches(all_predictions, all_true_labels)\n",
    "    token_f1 = calculate_token_f1(all_predictions, all_true_labels)\n",
    "    order_score = calculate_order_score(all_predictions, all_true_labels)\n",
    "    \n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    print(f\"Exact Match Accuracy: {exact_accuracy:.4f}\")\n",
    "    print(f\"Token F1 Score: {token_f1:.4f}\")\n",
    "    print(f\"Order Preservation Score: {order_score:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* best_model.pt   lr 1e-5 max_length 32,  batch 64,   accuracy  0.7679 0.9339 0.7889 \n",
    "* best_model1.pt  lr 1e-6 max_length 32,  batch 64,   accuracy  0.6697 0.8814 0.8814 \n",
    "* best_model2.pt  lr 3e-5 max_length 128, batch 32,   accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading t5-small model...\n",
      "Model and tokenizer loaded successfully\n",
      "Model loaded successfully!\n",
      "Generating predictions...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d56fa7d6b1864ecdaa71a78b29d79a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results:\n",
      "Exact Match Accuracy: 0.7939\n",
      "Token F1 Score: 0.9249\n",
      "Order Preservation Score: 0.7639\n"
     ]
    }
   ],
   "source": [
    "#normalizer = load_trained_model(model_path=\"best_model2.pt\")\n",
    "evaluate_model(normalizer, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(model_path=\"best_model.pt\", device=device):\n",
    "\n",
    "    # Initialize a new model instance\n",
    "    normalizer = TextNormalizer(device=device)\n",
    "    \n",
    "    # Load the saved state dictionary\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    normalizer.model.load_state_dict(state_dict)\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    normalizer.model.eval()\n",
    "    print(\"Model loaded successfully!\")\n",
    "    \n",
    "    return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading t5-small model...\n",
      "Model and tokenizer loaded successfully\n",
      "Model loaded successfully!\n",
      "Testing individual examples:\n",
      "\n",
      "Input: Mike Hoyer/JERRY CHESNUT/SONY/ATV MUSIC PUBLISHING\n",
      "Normalized: Mike Hoyer/JERRY CHESNUT/SONY\n",
      "\n",
      "Input: <Unknown>/Wright, Justyce Kaseem\n",
      "Normalized: Wright/Justyce Kaseem\n",
      "\n",
      "Input: Pixouu/Abdou Gambetta/Copyright Control\n",
      "Normalized: Pixouu/Abdou Gambetta\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "normalizer = load_trained_model(model_path=\"best_model2.pt\")\n",
    "\n",
    "# Test single examples\n",
    "test_texts = [\n",
    "    \"Mike Hoyer/JERRY CHESNUT/SONY/ATV MUSIC PUBLISHING\",\n",
    "    \"<Unknown>/Wright, Justyce Kaseem\",\n",
    "    \"Pixouu/Abdou Gambetta/Copyright Control\"\n",
    "]\n",
    "\n",
    "print(\"Testing individual examples:\")\n",
    "for text in test_texts:\n",
    "    normalized = normalizer.normalize_text(text)\n",
    "    print(f\"\\nInput: {text}\")\n",
    "    print(f\"Normalized: {normalized}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
