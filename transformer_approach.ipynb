{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import AdamW, get_scheduler\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Check if CUDA is available and set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv(\"normalization_assesment_dataset_10k.csv\")\n",
    "print(\"Dataset shape: \", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_na(df):\n",
    "    # Calculate null values for each column\n",
    "    null_counts = df.isnull().sum()\n",
    "    # Calculate percentage of null values\n",
    "    null_percentages = (null_counts / len(df)) * 100\n",
    "    print(\"null_percentages\", null_percentages)\n",
    "    if all(null_percentages[column] for column in df.columns) and df.shape[0] >= 10000:\n",
    "        new_df = df.dropna()\n",
    "        print(new_df.shape)\n",
    "        return new_df\n",
    "    return df\n",
    "\n",
    "\n",
    "df = handle_na(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    df[\"raw_comp_writers_text\"].values,\n",
    "    df[\"CLEAN_TEXT\"].values,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextNormalizationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        \"\"\"\n",
    "        Initialize the dataset for text normalization\n",
    "\n",
    "        Args:\n",
    "            texts (list): List of raw input texts\n",
    "            labels (list): List of normalized (clean) texts\n",
    "            tokenizer: T5 tokenizer instance\n",
    "            max_length (int): Maximum sequence length\n",
    "        \"\"\"\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Prepare input text with a task-specific prefix\n",
    "        input_text = f\"normalize: {self.texts[idx]}\"\n",
    "\n",
    "        # Tokenize input and target texts\n",
    "        input_encoding = self.tokenizer(\n",
    "            input_text,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        target_encoding = self.tokenizer(\n",
    "            self.labels[idx],\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": input_encoding[\"attention_mask\"].flatten(),\n",
    "            \"labels\": target_encoding[\"input_ids\"].flatten(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available T5 Model Variants\n",
    "Original T5 Family\n",
    "\n",
    "* t5-small (60M parameters)\n",
    "* t5-base (220M parameters)\n",
    "* t5-large (770M parameters)\n",
    "* t5-3b (3B parameters)\n",
    "* t5-11b (11B parameters)\n",
    "\n",
    "Flan-T5 (Instruction-tuned)\n",
    "\n",
    "* flan-t5-small\n",
    "* flan-t5-base\n",
    "* flan-t5-large\n",
    "* flan-t5-xl (3B parameters)\n",
    "* flan-t5-xxl (11B parameters)\n",
    "\n",
    "mT5 (Multilingual)\n",
    "\n",
    "* mt5-small\n",
    "* mt5-base\n",
    "* mt5-large\n",
    "* mt5-xl\n",
    "* mt5-xxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_used=\"google/mt5-base\"\n",
    "# Initialize tokenizer\n",
    "print(\"\\nInitializing tokenizer...\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_used)  # legacy= False\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TextNormalizationDataset(X_train, Y_train, tokenizer,max_length=16)\n",
    "val_dataset = TextNormalizationDataset(X_test, Y_test, tokenizer,max_length=16)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = max(len(tokenizer.encode(text)) for text in df['raw_comp_writers_text'])\n",
    "print(f\"Maximum tokens in dataset: {max_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextNormalizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name=model_used,\n",
    "        device=device,\n",
    "    ):\n",
    "        self.device = device\n",
    "        print(f\"Loading {model_name} model...\")\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "        print(\"Model and tokenizer loaded successfully\")\n",
    "\n",
    "    def train(self, train_loader, val_loader, epochs=3, lr=3e-5, patience=3):\n",
    "        \"\"\"\n",
    "        Train the model with early stopping\n",
    "        \n",
    "        Args:\n",
    "            train_loader: Training data loader\n",
    "            val_loader: Validation data loader\n",
    "            epochs (int): Maximum number of training epochs\n",
    "            lr (float): Learning rate\n",
    "            patience (int): Number of epochs to wait for improvement before stopping\n",
    "        \"\"\"\n",
    "        optimizer = AdamW(self.model.parameters(), lr=lr)\n",
    "        \n",
    "        # Define Scheduler\n",
    "        num_training_steps = epochs * len(train_loader)  # Total number of steps\n",
    "        num_warmup_steps = int(0.1 * num_training_steps)  # 10% warmup\n",
    "        scheduler = get_scheduler(\n",
    "        \"linear\", optimizer=optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps\n",
    "        )\n",
    "\n",
    "        \n",
    "        best_val_loss = float(\"inf\")\n",
    "        patience_counter = 0\n",
    "        best_model_state = None\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "            # Training loop\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "\n",
    "            for batch in progress_bar:\n",
    "                input_ids = batch[\"input_ids\"].to(self.device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(self.device)\n",
    "                labels = batch[\"labels\"].to(self.device)\n",
    "\n",
    "                outputs = self.model(\n",
    "                    input_ids=input_ids, \n",
    "                    attention_mask=attention_mask, \n",
    "                    labels=labels\n",
    "                )\n",
    "\n",
    "                loss = outputs.loss\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "            # Validation loop\n",
    "            val_loss = self.evaluate(val_loader)\n",
    "\n",
    "            # Print epoch statistics\n",
    "            avg_train_loss = train_loss / len(train_loader)\n",
    "            print(f\"Average training loss: {avg_train_loss:.4f}\")\n",
    "            print(f\"Average validation loss: {val_loss:.4f}\")\n",
    "\n",
    "            # Early stopping logic\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                best_model_state = self.model.state_dict().copy()\n",
    "                torch.save(best_model_state, \"best_model10.pt\")\n",
    "                print(\"Saved best model checkpoint\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                print(f\"Validation loss didn't improve. Patience: {patience_counter}/{patience}\")\n",
    "\n",
    "            # Check if we should stop training\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"\\nEarly stopping triggered after epoch {epoch + 1}\")\n",
    "                print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "                # Restore best model\n",
    "                self.model.load_state_dict(best_model_state)\n",
    "                break\n",
    "\n",
    "    def evaluate(self, val_loader):\n",
    "        \"\"\"\n",
    "        Evaluate the model on validation data\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        val_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "                input_ids = batch[\"input_ids\"].to(self.device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(self.device)\n",
    "                labels = batch[\"labels\"].to(self.device)\n",
    "\n",
    "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "                val_loss += outputs.loss.item()\n",
    "\n",
    "        return val_loss / len(val_loader)\n",
    "\n",
    "    def normalize_text(self, text):\n",
    "        \"\"\"\n",
    "        Normalize a single text input\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "\n",
    "        # Prepare input\n",
    "        input_text = f\"normalize: {text}\"\n",
    "        inputs = self.tokenizer(\n",
    "            input_text,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=128,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Generate output\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                max_length=128,\n",
    "                num_beams=4,\n",
    "                early_stopping=True,\n",
    "            )\n",
    "\n",
    "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "normalizer = TextNormalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer.train(train_loader, val_loader, epochs=30,patience=2,lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with some examples\n",
    "test_examples = [\n",
    "    \"Mike Hoyer/JERRY CHESNUT/SONY/ATV MUSIC PUBLISHING (UK) LIMITED\",\n",
    "    \"<Unknown>/Wright, Justyce Kaseem\",\n",
    "    \"Pixouu/Abdou Gambetta/Copyright Control\",\n",
    "]\n",
    "\n",
    "print(\"\\nTesting the model with examples:\")\n",
    "for text in test_examples:\n",
    "    normalized = normalizer.normalize_text(text)\n",
    "    print(f\"\\nInput: {text}\")\n",
    "    print(f\"Output: {normalized}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(normalizer, val_loader):\n",
    "    normalizer.model.eval()\n",
    "    exact_matches = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Calculating metrics\"):\n",
    "            input_ids = batch[\"input_ids\"].to(normalizer.device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(normalizer.device)\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            # Generate predictions\n",
    "            outputs = normalizer.model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=128,\n",
    "                num_beams=4,\n",
    "                early_stopping=True,\n",
    "                temperature=1.0,        \n",
    "                top_k=20,            \n",
    "                top_p=8.0,\n",
    "                repetition_penalty=1.0  \n",
    "            )\n",
    "\n",
    "            # Decode predictions and labels\n",
    "            predictions = [normalizer.tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "            true_labels = [normalizer.tokenizer.decode(label, skip_special_tokens=True) for label in labels]\n",
    "\n",
    "            # Calculate metrics\n",
    "            exact_matches += sum(1 for pred, true in zip(predictions, true_labels) if pred == true)\n",
    "            total += len(predictions)\n",
    "\n",
    "    accuracy = exact_matches / total\n",
    "    print(f\"\\nExact match accuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "accuracy = calculate_accuracy(normalizer, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_exact_matches(predictions, true_labels):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of predictions that exactly match their true labels\n",
    "    \"\"\"\n",
    "    matches = sum(1 for pred, true in zip(predictions, true_labels) if pred.strip() == true.strip())\n",
    "    return matches / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "\n",
    "def calculate_token_f1(predictions, true_labels):\n",
    "    \"\"\"\n",
    "    Calculate F1 score based on shared tokens between prediction and true label\n",
    "    \"\"\"\n",
    "    def tokenize(text):\n",
    "        # Split on common delimiters and create a set of tokens\n",
    "        return set(token.strip() for token in text.replace('/', ' ').split())\n",
    "    \n",
    "    all_true_tokens = []\n",
    "    all_pred_tokens = []\n",
    "    \n",
    "    for pred, true in zip(predictions, true_labels):\n",
    "        true_tokens = tokenize(true)\n",
    "        pred_tokens = tokenize(pred)\n",
    "        \n",
    "        # Convert to binary presence/absence for each token\n",
    "        all_tokens = true_tokens.union(pred_tokens)\n",
    "        all_true_tokens.extend(1 if token in true_tokens else 0 for token in all_tokens)\n",
    "        all_pred_tokens.extend(1 if token in pred_tokens else 0 for token in all_tokens)\n",
    "    \n",
    "    return f1_score(all_true_tokens, all_pred_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_order_score(predictions, true_labels):\n",
    "    \"\"\"\n",
    "    Calculate how well the model preserves the correct order of names\n",
    "    \"\"\"\n",
    "    def get_ordered_names(text):\n",
    "        return [name.strip() for name in text.split('/')]\n",
    "    \n",
    "    correct_order = 0\n",
    "    total_pairs = 0\n",
    "    \n",
    "    for pred, true in zip(predictions, true_labels):\n",
    "        pred_names = get_ordered_names(pred)\n",
    "        true_names = get_ordered_names(true)\n",
    "        \n",
    "        # Check relative ordering of each pair of names\n",
    "        for i in range(len(true_names)):\n",
    "            for j in range(i + 1, len(true_names)):\n",
    "                if i < len(pred_names) and j < len(pred_names):\n",
    "                    if (pred_names[i] in true_names and \n",
    "                        pred_names[j] in true_names):\n",
    "                        if (true_names.index(pred_names[i]) < \n",
    "                            true_names.index(pred_names[j])):\n",
    "                            correct_order += 1\n",
    "                    total_pairs += 1\n",
    "    \n",
    "    return correct_order / total_pairs if total_pairs > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(normalizer, val_loader):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation of the text normalization model\n",
    "    \"\"\"\n",
    "    normalizer.model.eval()\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "    \n",
    "    print(\"Generating predictions...\")\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader):\n",
    "            # Generate predictions\n",
    "            outputs = normalizer.model.generate(\n",
    "                input_ids=batch['input_ids'].to(normalizer.device),\n",
    "                attention_mask=batch['attention_mask'].to(normalizer.device),\n",
    "                max_length=32,\n",
    "                num_beams=4,\n",
    "                early_stopping=True,\n",
    "                temperature=1.0,        \n",
    "                top_k=20,            \n",
    "                top_p=8.0,\n",
    "                repetition_penalty=1.0  \n",
    "            )\n",
    "            \n",
    "            # Decode predictions and true labels\n",
    "            predictions = [normalizer.tokenizer.decode(output, skip_special_tokens=True) \n",
    "                         for output in outputs]\n",
    "            true_labels = [normalizer.tokenizer.decode(label, skip_special_tokens=True) \n",
    "                         for label in batch['labels']]\n",
    "            \n",
    "            all_predictions.extend(predictions)\n",
    "            all_true_labels.extend(true_labels)\n",
    "    \n",
    "    # Calculate all metrics\n",
    "    exact_accuracy = calculate_exact_matches(all_predictions, all_true_labels)\n",
    "    token_f1 = calculate_token_f1(all_predictions, all_true_labels)\n",
    "    order_score = calculate_order_score(all_predictions, all_true_labels)\n",
    "    \n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    print(f\"Exact Match Accuracy: {exact_accuracy:.4f}\")\n",
    "    print(f\"Token F1 Score: {token_f1:.4f}\")\n",
    "    print(f\"Order Preservation Score: {order_score:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## small\n",
    "* best_model.pt   lr 1e-5 max_length 32,  batch 64,   accuracy  0.7679 0.9339 0.7889 \n",
    "* best_model1.pt  lr 1e-6 max_length 32,  batch 64,   accuracy  0.6697 0.8814 0.8814 \n",
    "* best_model2.pt  lr 3e-5 max_length 128, batch 32,   accuracy  0.7939 0.9249 0.7639\n",
    "* best_model3.pt  lr 3e-5 max_length 32,  batch 64,   accuracy  0.7771 0.9311 0.7676\n",
    "* best_model4.pt  lr 1e-4 max_length 32,  batch 128,  accuracy  0.7771 0.9311 0.7676\n",
    "* best_model5.pt  lr 5e-5 max_length 128, batch 16,   accuracy  0.7858 0.9235 0.7408\n",
    "* best_model6.pt  lr 5e-5 max_length 32,  batch 16,   accuracy  0.7794 0.9317 0.7864\n",
    "* best_model7.pt  lr 1e-5 max_length 256, batch 16,   accuracy 0.7639 0.9183 0.7532\n",
    "  \n",
    "## google/mt5-small\n",
    "* best_model8.pt  lr 3e-5 max_length 16, batch 32,   accuracy  0 redo \n",
    "\n",
    "## google/mt5-base\n",
    "* best_model10.pt  lr 3e-5 max_length 16, batch 32,   accuracy  0 redo \n",
    "\n",
    "## google/flan-t5-small\n",
    "* best_model9.pt  lr 3e-5 max_length 16, batch 32,   accuracy  0.6189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizer = load_trained_model(model_path=\"best_model2.pt\")\n",
    "evaluate_model(normalizer, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(model_path=\"best_model10.pt\", device=device):\n",
    "\n",
    "    # Initialize a new model instance\n",
    "    normalizer = TextNormalizer(device=device)\n",
    "    \n",
    "    # Load the saved state dictionary\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    normalizer.model.load_state_dict(state_dict)\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    normalizer.model.eval()\n",
    "    print(\"Model loaded successfully!\")\n",
    "    \n",
    "    return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "normalizer = load_trained_model(model_path=\"best_model10.pt\")\n",
    "\n",
    "# Test single examples\n",
    "test_texts = [\n",
    "    \"Mike Hoyer/JERRY CHESNUT/SONY/ATV MUSIC PUBLISHING\",\n",
    "    \"<Unknown>/Wright, Justyce Kaseem\",\n",
    "    \"Pixouu/Abdou Gambetta/Copyright Control\",\n",
    "    \"Martin Hygård\",\n",
    "    \"MISIA/松井寛\",\n",
    "    \"Trần Quang Lộc\",\n",
    "    \"Александр Степанов (Alexandr Stepanov),Артём Иванов (Artyom Ivanov)\",\n",
    "    \"Oliv/김홍중/Peperoni/LEEZ/Ollounder/송민기/EDEN\",\n",
    "    \"栗林みな実/菊田大介\",\n",
    "    \"タブゾンビ\",\n",
    "    \"Afroto - عفروتو\",\n",
    "    \"ابو بكر سالم بلفقيه\",\n",
    "    \"กะลา/หนุ่ม กะลา/ธนา ชัยวรภัทร์\",\n",
    "]\n",
    "\n",
    "print(\"Testing individual examples:\")\n",
    "for text in test_texts:\n",
    "    normalized = normalizer.normalize_text(text)\n",
    "    print(f\"\\nInput: {text}\")\n",
    "    print(f\"Normalized: {normalized}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\n",
    "    # Publishing and Rights Management\n",
    "    'COPYRIGHT CONTROL', 'PUBLISHING', 'MUSIC PUBLISHING', 'ALL RIGHTS RESERVED',\n",
    "    'RIGHTS ADMINISTERED', 'RIGHTS MANAGED', 'RIGHTS CONTROLLED',\n",
    "    'PERFORMANCE RIGHTS', 'MECHANICAL RIGHTS', 'SYNC RIGHTS',\n",
    "    'ADMINISTERED BY', 'LICENSED TO', 'CONTROLLED BY', '<UNKNOWN>'\n",
    "    \n",
    "    # Business Entities\n",
    "    'LIMITED', 'LTD', 'LLC', 'INC', 'INCORPORATED', 'CORP', 'CORPORATION',\n",
    "    'GMBH', 'PTY', 'S.A.', 'N.V.', 'AG', 'CO', 'COMPANY',\n",
    "    \n",
    "    # Music Industry Terms\n",
    "    'MUSIC', 'SONGS', 'PRODUCTIONS', 'ENTERTAINMENT', 'RECORDS',\n",
    "    'RECORDINGS', 'LABEL', 'STUDIO', 'GROUP', 'BAND',\n",
    "    \n",
    "    # Major Companies and Common Affiliates\n",
    "    'SONY', 'ATV', 'SONY/ATV', 'BMG', 'EMI', 'UNIVERSAL',\n",
    "    'WARNER', 'WARNER CHAPPELL', 'KOBALT', 'BMI', 'ASCAP', 'SESAC',\n",
    "    'COLUMBIA', 'ATLANTIC', 'CAPITOL', 'MOTOWN', 'RCA',\n",
    "    \n",
    "    # Professional Designations\n",
    "    'MUSIKVERLAG', 'ÉDITIONS', 'EDITIONS', 'VERLAG',\n",
    "    'MUSIC GROUP', 'MEDIA', 'PARTNERS', 'ASSOCIATES',\n",
    "    \n",
    "    # Common Suffixes and Descriptors\n",
    "    'WORLDWIDE', 'INTERNATIONAL', 'GLOBAL', 'MANAGEMENT',\n",
    "    'HOLDINGS', 'VENTURES', 'ENTERPRISES', 'WORKS',\n",
    "    \n",
    "    # Rights Organizations\n",
    "    'PERFORMING RIGHTS', 'SOCIETY', 'ORGANIZATION', 'ASSOCIATION',\n",
    "    'COLLECTION SOCIETY', 'RIGHTS SOCIETY',\n",
    "    \n",
    "    # Digital and Modern Terms\n",
    "    'DIGITAL', 'DISTRIBUTION', 'STREAMING', 'LICENSING',\n",
    "    \n",
    "    # Legal and Administrative\n",
    "    'ADMINISTERED', 'REPRESENTS', 'REPRESENTED BY',\n",
    "    'ON BEHALF OF', 'C/O', 'CARE OF',\n",
    "    \n",
    "    # Geographical Indicators\n",
    "    '(UK)', '(US)', '(EU)', '(JP)', 'UK', 'USA', 'AMERICA',\n",
    "    'EUROPEAN', 'INTERNATIONAL', 'GLOBAL'\n",
    "]\n",
    "\n",
    "# Clean up the keywords list (remove duplicates, strip whitespace)\n",
    "keywords = list(set([k.strip() for k in keywords]))\n",
    "# Sort by length (longer phrases first to avoid partial replacements)\n",
    "keywords = sorted(keywords, key=len, reverse=True)\n",
    "print(keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "normalizer = load_trained_model(model_path=\"best_model10.pt\")\n",
    "\n",
    "# Test single examples\n",
    "test_texts = [\n",
    "    \"Mike Hoyer/JERRY CHESNUT/SONY/ATV MUSIC PUBLISHING\",\n",
    "    \"<Unknown>/Wright, Justyce Kaseem\",\n",
    "    \"Pixouu/Abdou Gambetta/Copyright Control\",\n",
    "    \"Martin Hygård\",\n",
    "    \"MISIA/松井寛\",\n",
    "    \"Trần Quang Lộc\",\n",
    "    \"Александр Степанов (Alexandr Stepanov),Артём Иванов (Artyom Ivanov)\",\n",
    "    \"Oliv/김홍중/Peperoni/LEEZ/Ollounder/송민기/EDEN\",\n",
    "    \"栗林みな実/菊田大介\",\n",
    "    \"タブゾンビ\",\n",
    "    \"Afroto - عفروتو\",\n",
    "    \"ابو بكر سالم بلفقيه\",\n",
    "    \"กะลา/หนุ่ม กะลา/ธนา ชัยวรภัทร์\",\n",
    "]\n",
    "\n",
    "print(\"Testing individual examples:\")\n",
    "for text in test_texts:\n",
    "    modified_text =  text\n",
    "    for word in text:\n",
    "        if word in keywords:\n",
    "            modified_text = text.replace(word,\" \")\n",
    "    normalized = normalizer.normalize_text(modified_text)\n",
    "    print(f\"\\nInput: {modified_text}\")\n",
    "    print(f\"Normalized: {normalized}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
