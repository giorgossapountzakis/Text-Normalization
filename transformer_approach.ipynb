{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import AdamW, get_scheduler\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Check if CUDA is available and set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (10000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_comp_writers_text</th>\n",
       "      <th>CLEAN_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jordan Riley/Adam Argyle/Martin Brammer</td>\n",
       "      <td>Jordan Riley/Adam Argyle/Martin Brammer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Martin Hygård</td>\n",
       "      <td>Martin Hygård</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jesse Robinson/Greg Phillips/Kishaun Bailey/Ka...</td>\n",
       "      <td>Jesse Robinson/Greg Phillips/Kishaun Bailey/Ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mendel Brikman</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alvin Lee</td>\n",
       "      <td>Alvin Lee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               raw_comp_writers_text  \\\n",
       "0            Jordan Riley/Adam Argyle/Martin Brammer   \n",
       "1                                      Martin Hygård   \n",
       "2  Jesse Robinson/Greg Phillips/Kishaun Bailey/Ka...   \n",
       "3                                     Mendel Brikman   \n",
       "4                                          Alvin Lee   \n",
       "\n",
       "                                          CLEAN_TEXT  \n",
       "0            Jordan Riley/Adam Argyle/Martin Brammer  \n",
       "1                                      Martin Hygård  \n",
       "2  Jesse Robinson/Greg Phillips/Kishaun Bailey/Ka...  \n",
       "3                                                NaN  \n",
       "4                                          Alvin Lee  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv(\"normalization_assesment_dataset_10k.csv\")\n",
    "print(\"Dataset shape: \", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CLEAN_TEXT\"] = df[\"CLEAN_TEXT\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def handle_na(df):\n",
    "#     # Calculate null values for each column\n",
    "#     null_counts = df.isnull().sum()\n",
    "#     # Calculate percentage of null values\n",
    "#     null_percentages = (null_counts / len(df)) * 100\n",
    "#     print(\"null_percentages\", null_percentages)\n",
    "#     if all(null_percentages[column] for column in df.columns) and df.shape[0] >= 10000:\n",
    "#         new_df = df.dropna()\n",
    "#         print(new_df.shape)\n",
    "#         return new_df\n",
    "#     return df\n",
    "\n",
    "\n",
    "# df = handle_na(df)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split: separate test set\n",
    "X_temp, X_test, Y_temp, Y_test = train_test_split(df[\"raw_comp_writers_text\"].values, df[\"CLEAN_TEXT\"].values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Second split: separate validation set from remaining data\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_temp, Y_temp, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training samples: 6000\n",
      "Validation samples: 2000\n",
      "Test samples: 2000\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTraining samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextNormalizationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        \"\"\"\n",
    "        dataset handler for text normalization\n",
    "        \"\"\"\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # we add 'normalize' as a task-specific prefix\n",
    "        input_text = f\"normalize: {self.texts[idx]}\"\n",
    "\n",
    "        # Tokenize input and target texts\n",
    "        input_encoding = self.tokenizer(\n",
    "            input_text,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        target_encoding = self.tokenizer(\n",
    "            self.labels[idx],\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": input_encoding[\"attention_mask\"].flatten(),\n",
    "            \"labels\": target_encoding[\"input_ids\"].flatten(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available T5 Model Variants\n",
    "Original T5 Family\n",
    "\n",
    "- t5-small (60M parameters)\n",
    "- t5-base (220M parameters)\n",
    "- t5-large (770M parameters)\n",
    "- t5-3b (3B parameters)\n",
    "- t5-11b (11B parameters)\n",
    "\n",
    "Flan-T5 (Instruction-tuned)\n",
    "\n",
    "- flan-t5-small\n",
    "- flan-t5-base\n",
    "- flan-t5-large\n",
    "- flan-t5-xl (3B parameters)\n",
    "- flan-t5-xxl (11B parameters)\n",
    "\n",
    "mT5 (Multilingual)\n",
    "\n",
    "- mt5-small\n",
    "- mt5-base\n",
    "- mt5-large\n",
    "- mt5-xl\n",
    "- mt5-xxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "model_used = \"t5-small\"\n",
    "# Initialize tokenizer\n",
    "print(\"\\nInitializing tokenizer...\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_used)  # legacy= False\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = TextNormalizationDataset(X_train, Y_train, tokenizer, max_length=32)\n",
    "val_dataset = TextNormalizationDataset(X_val, Y_val, tokenizer, max_length=32)\n",
    "test_dataset=TextNormalizationDataset(X_test, Y_test, tokenizer, max_length=32)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader=DataLoader(test_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextNormalizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_type=model_used,\n",
    "        device=device,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        main model function with train,evaluate, plot functions\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        print(f\"Loading {model_type} model...\")\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_type).to(device)\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(model_type)\n",
    "        print(\"Model and tokenizer loaded successfully\")\n",
    "\n",
    "    def train(self, train_loader, val_loader, epochs=3, lr=3e-5, patience=3):\n",
    "        \"\"\"\n",
    "        use trainloader for the data.\n",
    "        training  with lr scheduler\n",
    "        \"\"\"\n",
    "        optimizer = AdamW(self.model.parameters(), lr=lr)\n",
    "\n",
    "        # Scheduler\n",
    "        num_training_steps = epochs * len(train_loader)\n",
    "        num_warmup_steps = int(0.1 * num_training_steps)  # 10%\n",
    "        scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n",
    "\n",
    "        best_val_loss = float(\"inf\")\n",
    "        patience_counter = 0\n",
    "        best_model_state = None\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "            # training loop\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "\n",
    "            for batch in progress_bar:\n",
    "                input_ids = batch[\"input_ids\"].to(self.device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(self.device)\n",
    "                labels = batch[\"labels\"].to(self.device)\n",
    "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                train_loss += loss.item()\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "            # epoch validation\n",
    "            val_loss = self.evaluate(val_loader)\n",
    "\n",
    "            # Print epoch statistics\n",
    "            avg_train_loss = train_loss / len(train_loader)\n",
    "            print(f\"Average training loss: {avg_train_loss:.4f}\")\n",
    "            print(f\"Average validation loss: {val_loss:.4f}\")\n",
    "\n",
    "            # apply early stopping with patience\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                best_model_state = self.model.state_dict().copy()\n",
    "                torch.save(best_model_state, \"best_model14.pt\")\n",
    "                print(\"Saved best model checkpoint\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                print(f\"Validation loss didn't improve. Patience: {patience_counter}/{patience}\")\n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"\\nEarly stopping triggered after epoch {epoch + 1}\")\n",
    "                print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "                # load best model\n",
    "                self.model.load_state_dict(best_model_state)\n",
    "                break\n",
    "\n",
    "    def evaluate(self, val_loader):\n",
    "        \"\"\"\n",
    "        evulation function used in model validation\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        val_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "                input_ids = batch[\"input_ids\"].to(self.device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(self.device)\n",
    "                labels = batch[\"labels\"].to(self.device)\n",
    "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                val_loss += outputs.loss.item()\n",
    "\n",
    "        return val_loss / len(val_loader)\n",
    "\n",
    "    def normalize_text(self, text):\n",
    "        \"\"\"\n",
    "        Normalize a single text input\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "\n",
    "        # Prepare input\n",
    "        input_text = f\"normalize: {text}\"\n",
    "        inputs = self.tokenizer(\n",
    "            input_text,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=128,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Generate output\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                max_length=128,\n",
    "                num_beams=4,\n",
    "                early_stopping=True,\n",
    "            )\n",
    "\n",
    "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading t5-small model...\n",
      "Model and tokenizer loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "normalizer = TextNormalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa17c9e404c43a39214663801db606a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420b80f839714533894884372e54b485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 5.6452\n",
      "Average validation loss: 0.6251\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c59ae0a0b2f4dd0af3b67eff9d8a9d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecbf32a4c46e4649b1bdc14699ee5c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.1589\n",
      "Average validation loss: 0.5468\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c969245c5f7e4122881651d84b2841a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5c6cf97b16422c86e9cc7c24c7dcb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.5265\n",
      "Average validation loss: 0.2128\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7bc3aaa8cbb43af97f59a7bcf2c1abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313e8d8aa49942f6b47f4e0ba40079ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.2201\n",
      "Average validation loss: 0.1448\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52ac0ebfd7d4ec6946a69e6114731e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f309655acf46acab75f5f8ece771c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.1699\n",
      "Average validation loss: 0.1267\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a20cdb59924a36b95d8aeba2453858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29621f25d8146408556ef3bff716979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.1486\n",
      "Average validation loss: 0.1156\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79e7d673cba45c4b76e8530bf00f090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ed0b66b13e4b0e9ebda60d90f8535b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.1365\n",
      "Average validation loss: 0.1092\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e4b5e89f7c4eb79f80a5cd74ede682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf68790a0554a5395dc2d9e41f348c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.1290\n",
      "Average validation loss: 0.1047\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001f93887e2f4915863daf089fc5b8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9db181e8f14d1eba81dbb06b84e4c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.1205\n",
      "Average validation loss: 0.1018\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a8bb0cbcd54468a0a413d792ca1493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a8eb2079fc4588a575d7b36a712a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.1163\n",
      "Average validation loss: 0.0995\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e3b13a74024df0977fb65b99efb0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e8b10fdba24960a8bf26bdffd40754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.1131\n",
      "Average validation loss: 0.0968\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bfb6ff43b14819a9651bea7790ea32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23e2982e5c945ffae14d5f91947f63b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.1079\n",
      "Average validation loss: 0.0945\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "353fd1a0e0c946a38f426f04354c35e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef51fcde57441b8b0b5aaae1e6d78f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.1049\n",
      "Average validation loss: 0.0936\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0567451aba4f46d3959c1ce822e88ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ff1dbafc3040cc9ef4269b44a4d068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.1039\n",
      "Average validation loss: 0.0916\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5557ffb97ab94e5db54ece8f455d30d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f39c3896b441c7a0d9b64bdf779037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0994\n",
      "Average validation loss: 0.0908\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075b026d96d44f31849ade754a7e06ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888ee44b0c1d4b4c8c71ebc67e194414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0979\n",
      "Average validation loss: 0.0897\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff290244f2814fe1bc9801289c45b5fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea957fd7e1844df932c349ff28d7dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0956\n",
      "Average validation loss: 0.0893\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd30f4a89f748618bfe584645530825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6210ccec0cda4b5296e813a8dab29b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0925\n",
      "Average validation loss: 0.0885\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3709f33dbff34e94bb0bdf7ad1cef772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aac169725f34d0e9d7095ef0dc82f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0916\n",
      "Average validation loss: 0.0875\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed75e4e259ec43418e9124892473bef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee276beb5684a2ab174599f958e7d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0904\n",
      "Average validation loss: 0.0874\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38306e2f7c24ea5b4e83b273e994ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a90983fae644b2b0f69421e5dc1217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0891\n",
      "Average validation loss: 0.0866\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa29cee946a4ec7ac60451c0063d6d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa1b9f8b3dd42aaa8002b8c57b98cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0886\n",
      "Average validation loss: 0.0861\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52a58ac170f4060947d5b9e38d5fc4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e4e82b2473403d8a06d5cee32a8211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0868\n",
      "Average validation loss: 0.0859\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800a580f517c46e5bec2d504e54ee330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc355141c50743d8a2077800fba8f8a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0857\n",
      "Average validation loss: 0.0857\n",
      "Saved best model checkpoint\n",
      "\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdda1db9f8cb43b4b2bd8fe6ef82e171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5134c81eb4443f7b98cef2748481436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0840\n",
      "Average validation loss: 0.0859\n",
      "Validation loss didn't improve. Patience: 1/2\n",
      "\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c12e6699f3640c5a3fe9a47e0f238a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c440b7a3eecf4c45abab3509ba242b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0833\n",
      "Average validation loss: 0.0858\n",
      "Validation loss didn't improve. Patience: 2/2\n",
      "\n",
      "Early stopping triggered after epoch 26\n",
      "Best validation loss: 0.0857\n"
     ]
    }
   ],
   "source": [
    "normalizer.train(train_loader, val_loader, epochs=30, patience=2, lr=3e-5)  # 3e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing the model with examples:\n",
      "\n",
      "Input: Mike Hoyer/JERRY CHESNUT/SONY/ATV MUSIC PUBLISHING (UK) LIMITED\n",
      "Output: Mike Hoyer/JERRY CHESNUT/SONY\n",
      "\n",
      "Input: <Unknown>/Wright, Justyce Kaseem\n",
      "Output: Wright/Justyce Kaseem\n",
      "\n",
      "Input: Pixouu/Abdou Gambetta/Copyright Control\n",
      "Output: Pixouu/Abdou Gambetta\n"
     ]
    }
   ],
   "source": [
    "# Test the model with some examples\n",
    "test_examples = [\n",
    "    \"Mike Hoyer/JERRY CHESNUT/SONY/ATV MUSIC PUBLISHING (UK) LIMITED\",\n",
    "    \"<Unknown>/Wright, Justyce Kaseem\",\n",
    "    \"Pixouu/Abdou Gambetta/Copyright Control\",\n",
    "]\n",
    "\n",
    "print(\"\\nTesting the model with examples:\")\n",
    "for text in test_examples:\n",
    "    normalized = normalizer.normalize_text(text)\n",
    "    print(f\"\\nInput: {text}\")\n",
    "    print(f\"Output: {normalized}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(normalizer, test_loader):\n",
    "    normalizer.model.eval()\n",
    "    exact_matches = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Calculating metrics\"):\n",
    "            input_ids = batch[\"input_ids\"].to(normalizer.device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(normalizer.device)\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            # Generate predictions\n",
    "            outputs = normalizer.model.generate(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, max_length=128, num_beams=4, early_stopping=True, temperature=1.0, top_k=20, top_p=8.0, repetition_penalty=1.0\n",
    "            )\n",
    "\n",
    "            # Decode predictions and labels\n",
    "            predictions = [normalizer.tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "            true_labels = [normalizer.tokenizer.decode(label, skip_special_tokens=True) for label in labels]\n",
    "\n",
    "            # Calculate metrics\n",
    "            exact_matches += sum(1 for pred, true in zip(predictions, true_labels) if pred == true)\n",
    "            total += len(predictions)\n",
    "\n",
    "    accuracy = exact_matches / total\n",
    "    print(f\"\\nExact match accuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08069f6800ce4e8d87249ba4b868572f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating metrics:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exact match accuracy: 0.6520\n"
     ]
    }
   ],
   "source": [
    "accuracy = calculate_accuracy(normalizer, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_exact_matches(predictions, true_labels):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of predictions that exactly match their true labels\n",
    "    \"\"\"\n",
    "    matches = sum(1 for pred, true in zip(predictions, true_labels) if pred.strip() == true.strip())\n",
    "    return matches / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def calculate_token_f1(predictions, true_labels):\n",
    "    \"\"\"\n",
    "    Calculate F1 score based on shared tokens between prediction and true label\n",
    "    \"\"\"\n",
    "\n",
    "    def tokenize(text):\n",
    "        # Split on common delimiters and create a set of tokens\n",
    "        return set(token.strip() for token in text.replace(\"/\", \" \").split())\n",
    "\n",
    "    all_true_tokens = []\n",
    "    all_pred_tokens = []\n",
    "\n",
    "    for pred, true in zip(predictions, true_labels):\n",
    "        true_tokens = tokenize(true)\n",
    "        pred_tokens = tokenize(pred)\n",
    "\n",
    "        # Convert to binary presence/absence for each token\n",
    "        all_tokens = true_tokens.union(pred_tokens)\n",
    "        all_true_tokens.extend(1 if token in true_tokens else 0 for token in all_tokens)\n",
    "        all_pred_tokens.extend(1 if token in pred_tokens else 0 for token in all_tokens)\n",
    "\n",
    "    return f1_score(all_true_tokens, all_pred_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_order_score(predictions, true_labels):\n",
    "    \"\"\"\n",
    "    Calculate how well the model preserves the correct order of names\n",
    "    \"\"\"\n",
    "\n",
    "    def get_ordered_names(text):\n",
    "        return [name.strip() for name in text.split(\"/\")]\n",
    "\n",
    "    correct_order = 0\n",
    "    total_pairs = 0\n",
    "\n",
    "    for pred, true in zip(predictions, true_labels):\n",
    "        pred_names = get_ordered_names(pred)\n",
    "        true_names = get_ordered_names(true)\n",
    "\n",
    "        # Check relative ordering of each pair of names\n",
    "        for i in range(len(true_names)):\n",
    "            for j in range(i + 1, len(true_names)):\n",
    "                if i < len(pred_names) and j < len(pred_names):\n",
    "                    if pred_names[i] in true_names and pred_names[j] in true_names:\n",
    "                        if true_names.index(pred_names[i]) < true_names.index(pred_names[j]):\n",
    "                            correct_order += 1\n",
    "                    total_pairs += 1\n",
    "\n",
    "    return correct_order / total_pairs if total_pairs > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(normalizer, val_loader):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation of the text normalization model\n",
    "    \"\"\"\n",
    "    normalizer.model.eval()\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "\n",
    "    print(\"Generating predictions...\")\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader):\n",
    "            # Generate predictions\n",
    "            outputs = normalizer.model.generate(\n",
    "                input_ids=batch[\"input_ids\"].to(normalizer.device),\n",
    "                attention_mask=batch[\"attention_mask\"].to(normalizer.device),\n",
    "                max_length=32,\n",
    "                num_beams=4,\n",
    "                early_stopping=True,\n",
    "                temperature=1.0,\n",
    "                top_k=20,\n",
    "                top_p=8.0,\n",
    "                repetition_penalty=1.0,\n",
    "            )\n",
    "\n",
    "            # Decode predictions and true labels\n",
    "            predictions = [normalizer.tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "            true_labels = [normalizer.tokenizer.decode(label, skip_special_tokens=True) for label in batch[\"labels\"]]\n",
    "\n",
    "            all_predictions.extend(predictions)\n",
    "            all_true_labels.extend(true_labels)\n",
    "\n",
    "    # Calculate all metrics\n",
    "    exact_accuracy = calculate_exact_matches(all_predictions, all_true_labels)\n",
    "    token_f1 = calculate_token_f1(all_predictions, all_true_labels)\n",
    "    order_score = calculate_order_score(all_predictions, all_true_labels)\n",
    "\n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    print(f\"Exact Match Accuracy: {exact_accuracy:.4f}\")\n",
    "    print(f\"Token F1 Score: {token_f1:.4f}\")\n",
    "    print(f\"Order Preservation Score: {order_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## small\n",
    "\n",
    "- best_model.pt lr 1e-5 max_length 32, batch 64, accuracy 0.7679 0.9339 0.7889\n",
    "- best_model1.pt lr 1e-6 max_length 32, batch 64, accuracy 0.6697 0.8814 0.8814\n",
    "- best_model2.pt lr 3e-5 max_length 128, batch 32, accuracy 0.7939 0.9249 0.7639\n",
    "- best_model3.pt lr 3e-5 max_length 32, batch 64, accuracy 0.7771 0.9311 0.7676\n",
    "- best_model4.pt lr 1e-4 max_length 32, batch 128, accuracy 0.7771 0.9311 0.7676\n",
    "- best_model5.pt lr 5e-5 max_length 128, batch 16, accuracy 0.7858 0.9235 0.7408\n",
    "- best_model6.pt lr 5e-5 max_length 32, batch 16, accuracy 0.7794 0.9317 0.7864\n",
    "- best_model7.pt lr 1e-5 max_length 256, batch 16, accuracy 0.7639 0.9183 0.7532\n",
    "- best_model13.pt lr 1e-4 max_length 32, batch 64, accuracy 0.6\n",
    "- best_model14.pt lr 3e-4 max_length 64, batch 16, accuracy 0.6\n",
    "\n",
    "## base\n",
    "\n",
    "- best_model_11.pt lr 3e-5 max_length 16, batch 32, 0.6288 0.8761 0.4818\n",
    "\n",
    "## google/mt5-small\n",
    "\n",
    "- best_model8.pt lr 3e-5 max_length 16, batch 32, accuracy 0\n",
    "- best_model12.pt lr 3e-5 max_length 16, batch 8, accuracy 0.33\n",
    "\n",
    "## google/mt5-base\n",
    "\n",
    "cant use it\n",
    "\n",
    "## google/flan-t5-small\n",
    "\n",
    "- best_model9.pt lr 3e-5 max_length 16, batch 32, accuracy 0.6189\n",
    "- best_model10.pt lr 3e-5 max_length 16, batch 32, accuracy 0.6074 0.8714 0.4613\n",
    "- na dokimaso megalytero lr kai epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c251d20e15401bb04c2644f6484c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results:\n",
      "Exact Match Accuracy: 0.6520\n",
      "Token F1 Score: 0.8494\n",
      "Order Preservation Score: 0.7527\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(normalizer, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(model_path=None, model_type=None, device=device):\n",
    "\n",
    "    normalizer = TextNormalizer(model_type=model_type, device=device)\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    normalizer.model.load_state_dict(state_dict)\n",
    "    normalizer.model.eval()\n",
    "    print(\"Model loaded successfully!\")\n",
    "\n",
    "    return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading t5-small model...\n",
      "Model and tokenizer loaded successfully\n",
      "Model loaded successfully!\n",
      "Testing individual examples:\n",
      "\n",
      "Input: Mike Hoyer/JERRY CHESNUT/SONY/ATV MUSIC PUBLISHING\n",
      "Normalized: Mike Hoyer/JERRY CHESNUT/SONY\n",
      "\n",
      "Input: <Unknown>/Wright, Justyce Kaseem\n",
      "Normalized: Wright/Justyce Kaseem\n",
      "\n",
      "Input: Pixouu/Abdou Gambetta/Copyright Control\n",
      "Normalized: Pixouu/Abdou Gambetta\n",
      "\n",
      "Input: Martin Hygård\n",
      "Normalized: Martin Hygrd\n",
      "\n",
      "Input: MISIA/松井寛\n",
      "Normalized: MISIA/\n",
      "\n",
      "Input: Trần Quang Lộc\n",
      "Normalized: Trn Quang Lc\n",
      "\n",
      "Input: Александр Степанов (Alexandr Stepanov),Артём Иванов (Artyom Ivanov)\n",
      "Normalized: Alexandr Stepanov/Artyom Ivanov\n",
      "\n",
      "Input: Oliv/김홍중/Peperoni/LEEZ/Ollounder/송민기/EDEN\n",
      "Normalized: Oliv/Peperoni/LEEZ/Ollounder\n",
      "\n",
      "Input: 栗林みな実/菊田大介\n",
      "Normalized: \n",
      "\n",
      "Input: タブゾンビ\n",
      "Normalized: \n",
      "\n",
      "Input: Afroto - عفروتو\n",
      "Normalized: Afroto\n",
      "\n",
      "Input: ابو بكر سالم بلفقيه\n",
      "Normalized: \n",
      "\n",
      "Input: กะลา/หนุ่ม กะลา/ธนา ชัยวรภัทร์\n",
      "Normalized: \n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "normalizer = load_trained_model(model_path=\"best_model14.pt\", model_type=model_used)\n",
    "\n",
    "# Test single examples\n",
    "test_texts = [\n",
    "    \"Mike Hoyer/JERRY CHESNUT/SONY/ATV MUSIC PUBLISHING\",\n",
    "    \"<Unknown>/Wright, Justyce Kaseem\",\n",
    "    \"Pixouu/Abdou Gambetta/Copyright Control\",\n",
    "    \"Martin Hygård\",\n",
    "    \"MISIA/松井寛\",\n",
    "    \"Trần Quang Lộc\",\n",
    "    \"Александр Степанов (Alexandr Stepanov),Артём Иванов (Artyom Ivanov)\",\n",
    "    \"Oliv/김홍중/Peperoni/LEEZ/Ollounder/송민기/EDEN\",\n",
    "    \"栗林みな実/菊田大介\",\n",
    "    \"タブゾンビ\",\n",
    "    \"Afroto - عفروتو\",\n",
    "    \"ابو بكر سالم بلفقيه\",\n",
    "    \"กะลา/หนุ่ม กะลา/ธนา ชัยวรภัทร์\",\n",
    "]\n",
    "\n",
    "print(\"Testing individual examples:\")\n",
    "for text in test_texts:\n",
    "    normalized = normalizer.normalize_text(text)\n",
    "    print(f\"\\nInput: {text}\")\n",
    "    print(f\"Normalized: {normalized}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS-APPROACH EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "test_texts = [\n",
    "    \"Mike Hoyer/JERRY CHESNUT/SONY/ATV MUSIC PUBLISHING\",\n",
    "    \"<Unknown>/Wright, Justyce Kaseem\",\n",
    "    \"Pixouu/Abdou Gambetta/Copyright Control\",\n",
    "    \"Martin Hygård\",\n",
    "    \"MISIA/松井寛\",\n",
    "    \"Trần Quang Lộc\",\n",
    "    \"Александр Степанов (Alexandr Stepanov),Артём Иванов (Artyom Ivanov)\",\n",
    "    \"Oliv/김홍중/Peperoni/LEEZ/Ollounder/송민기/EDEN\",\n",
    "    \"栗林みな実/菊田大介\",\n",
    "    \"タブゾンビ\",\n",
    "    \"Afroto - عفروتو\",\n",
    "    \"ابو بكر سالم بلفقيه\",\n",
    "    \"กะลา/หนุ่ม กะลา/ธนา ชัยวรภัทร์\",\n",
    "]\n",
    "with open(\"script_stats.json\", \"r\") as f:\n",
    "    script_stats = json.load(f)\n",
    "with open(\"keywords.json\", \"r\") as f:\n",
    "    keywords = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heuristic_approach_2 import get_script_name\n",
    "def heuristic_clean_2(text):\n",
    "    with open(\"script_stats.json\", \"r\") as f:\n",
    "        script_stats = json.load(f)\n",
    "    modified_text=text\n",
    "    for char in text:\n",
    "        if char=='/':\n",
    "            continue\n",
    "        script = get_script_name(char)\n",
    "        if script_stats[script]['percentance']<0.5:\n",
    "            modified_text=modified_text.replace(char,'')\n",
    "    return modified_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def heuristic_clean(raw_text, keywords):\n",
    "   \"\"\"Clean text using heuristic rules\"\"\"\n",
    "   import string\n",
    "   \n",
    "   # Remove keywords\n",
    "   clean_text = raw_text\n",
    "   for keyword in keywords:\n",
    "       clean_text = clean_text.replace(keyword, '')\n",
    "   \n",
    "   # Replace & and comma with /\n",
    "   clean_text = clean_text.replace(' & ', '/').replace('&', '/').replace(',', '/')\n",
    "   \n",
    "   # Replace punctuation except / with space\n",
    "   trans = str.maketrans({p: ' ' for p in string.punctuation if p != '/'})\n",
    "   clean_text = clean_text.translate(trans)\n",
    "   \n",
    "   # Replace multiple spaces with single space\n",
    "   clean_text = ' '.join(clean_text.split())\n",
    "   \n",
    "   # Remove spaces around /\n",
    "   clean_text = re.sub(r'\\s*/\\s*', '/', clean_text)\n",
    "\n",
    "   return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds=[]\n",
    "heuristic_preds=[]\n",
    "heuristic_preds_2=[]\n",
    "for text in Y_test:\n",
    "    model_preds.append(normalizer.normalize_text(text))\n",
    "    heuristic_preds.append(heuristic_clean(text, keywords) )\n",
    "    heuristic_preds_2.append(heuristic_clean_2(text) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.728\n",
      "Model F1 Score: 0.727\n",
      "heuristic function 1 accuracy: 0.894\n",
      "heuristic function 1 F1 Score: 0.894\n",
      "heuristic function 2 accuracy: 1.000\n",
      "heuristic function 2 F1 Score: 1.000\n",
      "\n",
      "Example predictions:\n",
      "\n",
      "Input: Endo Anaconda/Balts Nill\n",
      "Expected: Endo Anaconda/Balts Nill\n",
      "Predicted using the model: Endo Anaconda/Balts Nill\n",
      "Predicted using heuristic function 1: Endo Anaconda/Balts Nill\n",
      "Predicted using heuristic function 2: Endo Anaconda/Balts Nill\n",
      "\n",
      "Input: Jessica Curry\n",
      "Expected: Jessica Curry\n",
      "Predicted using the model: Jessica Curry\n",
      "Predicted using heuristic function 1: Jessica Curry\n",
      "Predicted using heuristic function 2: Jessica Curry\n",
      "\n",
      "Input: Peter Kelly/Andy Monaghan/Jill O'Sullivan\n",
      "Expected: Peter Kelly/Andy Monaghan/Jill O'Sullivan\n",
      "Predicted using the model: Peter Kelly/Andy Monaghan\n",
      "Predicted using heuristic function 1: Peter Kelly/Andy Monaghan/Jill O Sullivan\n",
      "Predicted using heuristic function 2: Peter Kelly/Andy Monaghan/Jill O'Sullivan\n",
      "\n",
      "Input: Thomas Bergersen/Nick Phoenix\n",
      "Expected: Thomas Bergersen/Nick Phoenix\n",
      "Predicted using the model: Thomas Bergersen/Nick Phoenix\n",
      "Predicted using heuristic function 1: Thomas Bergersen/Nick Phoenix\n",
      "Predicted using heuristic function 2: Thomas Bergersen/Nick Phoenix\n",
      "\n",
      "Input: Candelaria Tojin\n",
      "Expected: Candelaria Tojin\n",
      "Predicted using the model: Candelaria Tojin\n",
      "Predicted using heuristic function 1: Candelaria Tojin\n",
      "Predicted using heuristic function 2: Candelaria Tojin\n",
      "\n",
      "Input: 传统音乐 & 李富兴\n",
      "Expected: \n",
      "Predicted using the model: \n",
      "Predicted using heuristic function 1: \n",
      "Predicted using heuristic function 2: \n",
      "\n",
      "Input: Rob Hubbard\n",
      "Expected: Rob Hubbard\n",
      "Predicted using the model: Rob Hubbard\n",
      "Predicted using heuristic function 1: Rob Hubbard\n",
      "Predicted using heuristic function 2: Rob Hubbard\n",
      "\n",
      "Input: Sony Assla/V. Kainth\n",
      "Expected: \n",
      "Predicted using the model: \n",
      "Predicted using heuristic function 1: \n",
      "Predicted using heuristic function 2: \n",
      "\n",
      "Input: Salomon Hermann Mosenthal/Anton Rubinstein\n",
      "Expected: Salomon Hermann Mosenthal/Anton Rubinstein\n",
      "Predicted using the model: Salomon Hermann Mosenthal/Anton Rubinstein\n",
      "Predicted using heuristic function 1: Salomon Hermann Mosenthal/Anton Rubinstein\n",
      "Predicted using heuristic function 2: Salomon Hermann Mosenthal/Anton Rubinstein\n",
      "\n",
      "Input: Todd Christensen\n",
      "Expected: Todd Christensen\n",
      "Predicted using the model: Todd Christensen\n",
      "Predicted using heuristic function 1: Todd Christensen\n",
      "Predicted using heuristic function 2: Todd Christensen\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "accuracy = [accuracy_score(Y_test, y_pred) for y_pred in [model_preds,heuristic_preds,heuristic_preds_2]]\n",
    "f1 = [f1_score(Y_test, y_pred, average='weighted') for y_pred in [model_preds,heuristic_preds,heuristic_preds_2]]\n",
    "\n",
    "\n",
    "print(f'Model accuracy: {accuracy[0]:.3f}')\n",
    "print(f'Model F1 Score: {f1[0]:.3f}')\n",
    "print(f'heuristic function 1 accuracy: {accuracy[1]:.3f}')\n",
    "print(f'heuristic function 1 F1 Score: {f1[1]:.3f}')\n",
    "print(f'heuristic function 2 accuracy: {accuracy[2]:.3f}')\n",
    "print(f'heuristic function 2 F1 Score: {f1[2]:.3f}')\n",
    "\n",
    "# some examples\n",
    "print('\\nExample predictions:')\n",
    "for i in range(10):\n",
    "   print(f'\\nInput: {X_test[i]}')\n",
    "   print(f'Expected: {Y_test[i]}')\n",
    "   print(f'Predicted using the model: {model_preds[i]}')\n",
    "   print(f'Predicted using heuristic function 1: {heuristic_preds[i]}')\n",
    "   print(f'Predicted using heuristic function 2: {heuristic_preds_2[i]}')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model performance after applying heuristic function 1 to the inputs\n",
      "Model accuracy: 0.728\n",
      "Model F1 Score: 0.727\n"
     ]
    }
   ],
   "source": [
    "print(\"model performance after applying heuristic function 1 to the inputs\")\n",
    "model_preds=[]\n",
    "for text in heuristic_preds:\n",
    "    model_preds.append(normalizer.normalize_text(text))\n",
    "\n",
    "accuracy = accuracy_score(Y_test, model_preds)\n",
    "f1 = f1_score(Y_test, model_preds, average='weighted') \n",
    "\n",
    "\n",
    "print(f'Model accuracy: {accuracy:.3f}')\n",
    "print(f'Model F1 Score: {f1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model performance after applying heuristic function 2 to the inputs\n",
      "Model accuracy: 0.774\n",
      "Model F1 Score: 0.773\n"
     ]
    }
   ],
   "source": [
    "print(\"model performance after applying heuristic function 2 to the inputs\")\n",
    "model_preds=[]\n",
    "for text in heuristic_preds_2:\n",
    "    model_preds.append(normalizer.normalize_text(text))\n",
    "\n",
    "accuracy = accuracy_score(Y_test, model_preds)\n",
    "f1 = f1_score(Y_test, model_preds, average='weighted') \n",
    "\n",
    "\n",
    "print(f'Model accuracy: {accuracy:.3f}')\n",
    "print(f'Model F1 Score: {f1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model performance after applying both heuristic functions to the inputs\n",
      "Model accuracy: 0.728\n",
      "Model F1 Score: 0.727\n"
     ]
    }
   ],
   "source": [
    "print(\"model performance after applying both heuristic functions to the inputs\")\n",
    "model_preds=[]\n",
    "for text in heuristic_preds:\n",
    "    model_preds.append(normalizer.normalize_text(heuristic_clean_2(text) ))\n",
    "\n",
    "accuracy = accuracy_score(Y_test, model_preds)\n",
    "f1 = f1_score(Y_test, model_preds, average='weighted') \n",
    "\n",
    "\n",
    "print(f'Model accuracy: {accuracy:.3f}')\n",
    "print(f'Model F1 Score: {f1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
